# Implementing_Cache_in_C
Memory access has come a long way since the early years of computing.  Through experimentation, brilliant innovators have improved memory by reducing memory misses and access times by invoking different cache methods within relation to the CPU.  In this paper, we will explain our experimentation with miss rates and average memory access times with common cache architecture, level 1 cache and level 2 cache, compared to adding victim cache and level 3 cache by using SimpleScalar as a simulation. The structure of the cache is when there is a miss at L1, we check if there is hit at victim cache if there is a hit well and good or else, we need to check one-layer lower which is L2 and so on. The result is the comparison of access rate when we add more cache to the existing L1 and L2 architecture. Based on the paper there are two architectures that helps us optimize and improve the performance of the system. The first architecture is adding the L3 to the existing L2 cache and thus by reducing the access to the main memory. The second architecture is by adding victim cache to the L1 cache thus by improving the performance of the system considerably. Both the architectures are implemented, and the result is compared for their performance. The model with which the victim cache was implemented showed a higher reduction of miss rate and reduces the number of access that go to main memory with improved processor performance. Based on the miss rate we plotted the graph and result is discussed.
